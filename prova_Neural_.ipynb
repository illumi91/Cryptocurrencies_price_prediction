{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the lenght of the sequence (SEQ_LEN) that we will be using to predict a certain cryptocurrency (RATIO_TO_PREDICT) into a future time (FUTURE_PERIOD_PREDICT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 72  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict\n",
    "RATIO_TO_PREDICT = \"ETHTUSD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as we did for machine learning we will be creating our labels based on a % change in prices for our cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(future):\n",
    "    '''Return 1, 0, 2 based on % change\n",
    "    \n",
    "       Args:\n",
    "           future: price timeseries lagged into future\n",
    "    '''\n",
    "    change_perc = 0.01\n",
    "    \n",
    "    if future > change_perc:\n",
    "        return 1\n",
    "    if future < -change_perc:\n",
    "        return 0\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    '''Define labels X, y creating a column containing the values of the price difference normalized\n",
    "       based on the hours we want to predict in future\n",
    "    \n",
    "       Args:\n",
    "           df: df containing closing prices for cryptocurrencies we want to predict\n",
    "           \n",
    "       Returns:\n",
    "           np.array(X): sequences we will use as feature to predict\n",
    "           y: target variable\n",
    "    '''\n",
    "    df = df.drop(\"pct_change\", 1)  # don't need this anymore.\n",
    "    for col in df.columns:  # go through all of the columns\n",
    "        if col != \"target\":  # normalize all ... except for the target itself!\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.fillna(method='ffill')  # remove the nas created by pct_change\n",
    "            df = df.replace([np.inf, -np.inf], 0)\n",
    "            df.fillna(0, inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # cleanup again... \n",
    "\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. \n",
    "    \n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "    \n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "    holds = []  # list that will store our sell sequences and targets\n",
    "    \n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "        else:\n",
    "            holds.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "    random.shuffle(holds)  # shuffle the holds!\n",
    "    \n",
    "    lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "    \n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    \n",
    "    sequential_data = buys+sells+holds  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define 5 symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = ['BTCTUSD', \"ETHTUSD\" , \"XRPTUSD\", \"LTCTUSD\", \"EOSTUSD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create main df with close prices and volume for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCTUSD\n",
      "ETHTUSD\n",
      "XRPTUSD\n",
      "LTCTUSD\n",
      "EOSTUSD\n",
      "               BTCTUSD_close  BTCTUSD_volume  ETHTUSD_close  ETHTUSD_volume  \\\n",
      "Time                                                                          \n",
      "1581346800000        9914.98       42.847840         224.48       437.23191   \n",
      "1581343200000        9867.88       10.544541         223.24       921.30562   \n",
      "1581339600000        9811.44       12.148842         219.41       672.55340   \n",
      "1581336000000        9838.86       10.340284         219.73       279.35173   \n",
      "1581332400000        9807.88       22.957431         217.91       203.97147   \n",
      "\n",
      "               XRPTUSD_close  XRPTUSD_volume  LTCTUSD_close  LTCTUSD_volume  \\\n",
      "Time                                                                          \n",
      "1581346800000        0.27595        150520.2          74.87      1236.85021   \n",
      "1581343200000        0.27370         20433.0          74.44       300.63211   \n",
      "1581339600000        0.27156          9748.0          73.41       227.99520   \n",
      "1581336000000        0.27188         13476.4          73.49        91.53713   \n",
      "1581332400000        0.27007          9632.8          73.05       267.58230   \n",
      "\n",
      "               EOSTUSD_close  EOSTUSD_volume  \n",
      "Time                                          \n",
      "1581346800000         4.9057          138.60  \n",
      "1581343200000         4.9100           20.00  \n",
      "1581339600000         4.8321          760.33  \n",
      "1581336000000         4.8150          176.16  \n",
      "1581332400000         4.7682          523.45  \n"
     ]
    }
   ],
   "source": [
    "crp_df = pd.DataFrame() # begin empty\n",
    "\n",
    "for ratio in ratios:  # begin iteration\n",
    "    print(ratio)\n",
    "    dataset = f'crypto_dfs/{ratio}.csv'  # get the full path to the file.\n",
    "    \n",
    "    df = pd.read_csv(dataset, index_col=0)  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"Close\": f\"{ratio}_close\", \"Volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"Time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    \n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    if len(crp_df)==0:  # if the dataframe is empty\n",
    "        crp_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        crp_df = crp_df.join(df)\n",
    "\n",
    "print(crp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag price into future through pct_change.\n",
    "\n",
    "In our case 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581346800000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>224.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581343200000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>223.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581339600000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>219.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581336000000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>219.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581332400000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>217.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pct_change  ETHTUSD_close\n",
       "Time                                    \n",
       "1581346800000         NaN         224.48\n",
       "1581343200000         NaN         223.24\n",
       "1581339600000         NaN         219.41\n",
       "1581336000000         NaN         219.73\n",
       "1581332400000         NaN         217.91"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df['pct_change'] = crp_df[[f'{RATIO_TO_PREDICT}_close']].pct_change(24)\n",
    "crp_df[['pct_change', f'{RATIO_TO_PREDICT}_close']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply our previous function to get our target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crp_df['target'] = crp_df['pct_change'].map(buy_sell_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.350962\n",
       "1    0.326122\n",
       "2    0.322917\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split df in 2 parts for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(crp_df.index.values)  # get the times\n",
    "last_20pct = sorted(crp_df.index.values)[-int(0.2*len(times))]  # get the last 20% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_main_df = crp_df[(crp_df.index >= last_20pct)]  # make the validation data where the index is in the last 5%\n",
    "main_df = crp_df[(crp_df.index < last_20pct)]  # now the main_df is all the data up to the last 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1779 Validation: 282\n",
      "Sells: 593, Holds: 593, Buys: 593\n",
      "VALIDATION Sells: 94, Holds: 94, buys: 94\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"Train data: {len(train_x)} Validation: {len(validation_x)}\")\n",
    "print(f\"Sells: {train_y.count(0)}, Holds: {train_y.count(2)}, Buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Sells: {validation_y.count(0)}, Holds: {validation_y.count(2)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a few more constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20  # how many passes through our data\n",
    "BATCH_SIZE = 64  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "\n",
    "filepath = \"LSTM_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "# unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) \n",
    "# saves only the best ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1779 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "1779/1779 [==============================] - 10s 5ms/step - loss: 4.2675 - acc: 0.5677 - val_loss: 1.8579 - val_acc: 0.5603\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.8579343007811417\n",
      "Test accuracy: 0.5602836900569023\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad start. Better than random, validation accuracy rises over time, validation loss drops.\n",
    "\n",
    "Changing the name constant to include the ratio we're predicting:\n",
    "\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "And then testing against all of the ratios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "crp_df_500 = pd.DataFrame() # begin empty\n",
    "\n",
    "for ratio in ratios:  # begin iteration\n",
    "    dataset = f'crypto_dfs/{ratio}.csv'  # get the full path to the file.\n",
    "    \n",
    "    df = pd.read_csv(dataset, index_col=0)  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"Close\": f\"{ratio}_close\", \"Volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"Time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    \n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    \n",
    "    if len(crp_df_500)==0:  # if the dataframe is empty\n",
    "        crp_df_500 = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        crp_df_500 = crp_df_500.merge(df, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df_500.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCTUSD_close</th>\n",
       "      <th>BTCTUSD_volume</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "      <th>ETHTUSD_volume</th>\n",
       "      <th>XRPTUSD_close</th>\n",
       "      <th>XRPTUSD_volume</th>\n",
       "      <th>LTCTUSD_close</th>\n",
       "      <th>LTCTUSD_volume</th>\n",
       "      <th>EOSTUSD_close</th>\n",
       "      <th>EOSTUSD_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581346800000</th>\n",
       "      <td>9914.98</td>\n",
       "      <td>42.847840</td>\n",
       "      <td>224.48</td>\n",
       "      <td>437.23191</td>\n",
       "      <td>0.27595</td>\n",
       "      <td>150520.2</td>\n",
       "      <td>74.87</td>\n",
       "      <td>1236.85021</td>\n",
       "      <td>4.9057</td>\n",
       "      <td>138.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581343200000</th>\n",
       "      <td>9867.88</td>\n",
       "      <td>10.544541</td>\n",
       "      <td>223.24</td>\n",
       "      <td>921.30562</td>\n",
       "      <td>0.27370</td>\n",
       "      <td>20433.0</td>\n",
       "      <td>74.44</td>\n",
       "      <td>300.63211</td>\n",
       "      <td>4.9100</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581339600000</th>\n",
       "      <td>9811.44</td>\n",
       "      <td>12.148842</td>\n",
       "      <td>219.41</td>\n",
       "      <td>672.55340</td>\n",
       "      <td>0.27156</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>73.41</td>\n",
       "      <td>227.99520</td>\n",
       "      <td>4.8321</td>\n",
       "      <td>760.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581336000000</th>\n",
       "      <td>9838.86</td>\n",
       "      <td>10.340284</td>\n",
       "      <td>219.73</td>\n",
       "      <td>279.35173</td>\n",
       "      <td>0.27188</td>\n",
       "      <td>13476.4</td>\n",
       "      <td>73.49</td>\n",
       "      <td>91.53713</td>\n",
       "      <td>4.8150</td>\n",
       "      <td>176.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581332400000</th>\n",
       "      <td>9807.88</td>\n",
       "      <td>22.957431</td>\n",
       "      <td>217.91</td>\n",
       "      <td>203.97147</td>\n",
       "      <td>0.27007</td>\n",
       "      <td>9632.8</td>\n",
       "      <td>73.05</td>\n",
       "      <td>267.58230</td>\n",
       "      <td>4.7682</td>\n",
       "      <td>523.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BTCTUSD_close  BTCTUSD_volume  ETHTUSD_close  ETHTUSD_volume  \\\n",
       "Time                                                                          \n",
       "1581346800000        9914.98       42.847840         224.48       437.23191   \n",
       "1581343200000        9867.88       10.544541         223.24       921.30562   \n",
       "1581339600000        9811.44       12.148842         219.41       672.55340   \n",
       "1581336000000        9838.86       10.340284         219.73       279.35173   \n",
       "1581332400000        9807.88       22.957431         217.91       203.97147   \n",
       "\n",
       "               XRPTUSD_close  XRPTUSD_volume  LTCTUSD_close  LTCTUSD_volume  \\\n",
       "Time                                                                          \n",
       "1581346800000        0.27595        150520.2          74.87      1236.85021   \n",
       "1581343200000        0.27370         20433.0          74.44       300.63211   \n",
       "1581339600000        0.27156          9748.0          73.41       227.99520   \n",
       "1581336000000        0.27188         13476.4          73.49        91.53713   \n",
       "1581332400000        0.27007          9632.8          73.05       267.58230   \n",
       "\n",
       "               EOSTUSD_close  EOSTUSD_volume  \n",
       "Time                                          \n",
       "1581346800000         4.9057          138.60  \n",
       "1581343200000         4.9100           20.00  \n",
       "1581339600000         4.8321          760.33  \n",
       "1581336000000         4.8150          176.16  \n",
       "1581332400000         4.7682          523.45  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df_500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581346800000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>224.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581343200000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>223.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581339600000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>219.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581336000000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>219.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581332400000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>217.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pct_change  ETHTUSD_close\n",
       "Time                                    \n",
       "1581346800000         NaN         224.48\n",
       "1581343200000         NaN         223.24\n",
       "1581339600000         NaN         219.41\n",
       "1581336000000         NaN         219.73\n",
       "1581332400000         NaN         217.91"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df_500['pct_change'] = crp_df_500[[f'{RATIO_TO_PREDICT}_close']].pct_change(24)\n",
    "crp_df_500[['pct_change', f'{RATIO_TO_PREDICT}_close']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "crp_df_500['target'] = crp_df_500['pct_change'].map(buy_sell_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.350962\n",
       "1    0.326122\n",
       "2    0.322917\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df_500['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(crp_df_500.index.values)  # get the times\n",
    "last_20pct = sorted(crp_df_500.index.values)[-int(0.2*len(times))]  # get the last 20% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_main_df = crp_df_500[(crp_df_500.index >= last_20pct)]  # make the validation data where the index is in the last 5%\n",
    "main_df = crp_df_500[(crp_df_500.index < last_20pct)]  # now the main_df is all the data up to the last 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1779 Validation: 282\n",
      "Sells: 593, Holds: 593, Buys: 593\n",
      "VALIDATION Sells: 94, Holds: 94, buys: 94\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"Train data: {len(train_x)} Validation: {len(validation_x)}\")\n",
    "print(f\"Sells: {train_y.count(0)}, Holds: {train_y.count(2)}, Buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Sells: {validation_y.count(0)}, Holds: {validation_y.count(2)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a few more constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1  # how many passes through our data\n",
    "BATCH_SIZE = 64  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've normalized and scaled the data! Next up, we need to create our actual sequences. To do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "\n",
    "filepath = \"LSTM_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "# unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) \n",
    "# saves only the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1779 samples, validate on 282 samples\n",
      "Epoch 1/1\n",
      "1779/1779 [==============================] - 12s 7ms/step - loss: 2.8089 - acc: 0.5076 - val_loss: 1.7001 - val_acc: 0.5284\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7000970772817625\n",
      "Test accuracy: 0.5283687939035132\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "#model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 5 ratios and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "crp_df = pd.DataFrame() # begin empty\n",
    "ratios = ['BTCTUSD', \"ETHTUSD\" , \"XRPTUSD\", \"LTCTUSD\", \"EOSTUSD\"]\n",
    "\n",
    "for ratio in ratios:  # begin iteration\n",
    "    dataset = f'crypto_dfs/{ratio}.csv'  # get the full path to the file.\n",
    "    \n",
    "    df = pd.read_csv(dataset, index_col=0)  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"Close\": f\"{ratio}_close\", \"Volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"Time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    \n",
    "    df[f'{ratio}_pct_change'] = df[[f'{ratio}_close']].pct_change(1)\n",
    "    \n",
    "    df[f'{ratio}_target'] = df[f'{ratio}_pct_change'].map(buy_sell_hold)\n",
    "    \n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\", f'{ratio}_pct_change', f'{ratio}_target']]  # ignore the other columns besides price and volume\n",
    "\n",
    "    \n",
    "    if len(crp_df)==0:  # if the dataframe is empty\n",
    "        crp_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        crp_df = crp_df.merge(df, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCTUSD_close</th>\n",
       "      <th>BTCTUSD_volume</th>\n",
       "      <th>BTCTUSD_pct_change</th>\n",
       "      <th>BTCTUSD_target</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "      <th>ETHTUSD_volume</th>\n",
       "      <th>ETHTUSD_pct_change</th>\n",
       "      <th>ETHTUSD_target</th>\n",
       "      <th>XRPTUSD_close</th>\n",
       "      <th>XRPTUSD_volume</th>\n",
       "      <th>XRPTUSD_pct_change</th>\n",
       "      <th>XRPTUSD_target</th>\n",
       "      <th>LTCTUSD_close</th>\n",
       "      <th>LTCTUSD_volume</th>\n",
       "      <th>LTCTUSD_pct_change</th>\n",
       "      <th>LTCTUSD_target</th>\n",
       "      <th>EOSTUSD_close</th>\n",
       "      <th>EOSTUSD_volume</th>\n",
       "      <th>EOSTUSD_pct_change</th>\n",
       "      <th>EOSTUSD_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581346800000</th>\n",
       "      <td>9914.98</td>\n",
       "      <td>42.847840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>224.48</td>\n",
       "      <td>437.23191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.27595</td>\n",
       "      <td>150520.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>74.87</td>\n",
       "      <td>1236.85021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9057</td>\n",
       "      <td>138.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581343200000</th>\n",
       "      <td>9867.88</td>\n",
       "      <td>10.544541</td>\n",
       "      <td>-0.004750</td>\n",
       "      <td>2</td>\n",
       "      <td>223.24</td>\n",
       "      <td>921.30562</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>2</td>\n",
       "      <td>0.27370</td>\n",
       "      <td>20433.0</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>2</td>\n",
       "      <td>74.44</td>\n",
       "      <td>300.63211</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9100</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581339600000</th>\n",
       "      <td>9811.44</td>\n",
       "      <td>12.148842</td>\n",
       "      <td>-0.005720</td>\n",
       "      <td>2</td>\n",
       "      <td>219.41</td>\n",
       "      <td>672.55340</td>\n",
       "      <td>-0.017156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27156</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>-0.007819</td>\n",
       "      <td>2</td>\n",
       "      <td>73.41</td>\n",
       "      <td>227.99520</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8321</td>\n",
       "      <td>760.33</td>\n",
       "      <td>-0.015866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581336000000</th>\n",
       "      <td>9838.86</td>\n",
       "      <td>10.340284</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>2</td>\n",
       "      <td>219.73</td>\n",
       "      <td>279.35173</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>2</td>\n",
       "      <td>0.27188</td>\n",
       "      <td>13476.4</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>2</td>\n",
       "      <td>73.49</td>\n",
       "      <td>91.53713</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8150</td>\n",
       "      <td>176.16</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581332400000</th>\n",
       "      <td>9807.88</td>\n",
       "      <td>22.957431</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>2</td>\n",
       "      <td>217.91</td>\n",
       "      <td>203.97147</td>\n",
       "      <td>-0.008283</td>\n",
       "      <td>2</td>\n",
       "      <td>0.27007</td>\n",
       "      <td>9632.8</td>\n",
       "      <td>-0.006657</td>\n",
       "      <td>2</td>\n",
       "      <td>73.05</td>\n",
       "      <td>267.58230</td>\n",
       "      <td>-0.005987</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7682</td>\n",
       "      <td>523.45</td>\n",
       "      <td>-0.009720</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BTCTUSD_close  BTCTUSD_volume  BTCTUSD_pct_change  \\\n",
       "Time                                                               \n",
       "1581346800000        9914.98       42.847840                 NaN   \n",
       "1581343200000        9867.88       10.544541           -0.004750   \n",
       "1581339600000        9811.44       12.148842           -0.005720   \n",
       "1581336000000        9838.86       10.340284            0.002795   \n",
       "1581332400000        9807.88       22.957431           -0.003149   \n",
       "\n",
       "               BTCTUSD_target  ETHTUSD_close  ETHTUSD_volume  \\\n",
       "Time                                                           \n",
       "1581346800000               2         224.48       437.23191   \n",
       "1581343200000               2         223.24       921.30562   \n",
       "1581339600000               2         219.41       672.55340   \n",
       "1581336000000               2         219.73       279.35173   \n",
       "1581332400000               2         217.91       203.97147   \n",
       "\n",
       "               ETHTUSD_pct_change  ETHTUSD_target  XRPTUSD_close  \\\n",
       "Time                                                               \n",
       "1581346800000                 NaN               2        0.27595   \n",
       "1581343200000           -0.005524               2        0.27370   \n",
       "1581339600000           -0.017156               0        0.27156   \n",
       "1581336000000            0.001458               2        0.27188   \n",
       "1581332400000           -0.008283               2        0.27007   \n",
       "\n",
       "               XRPTUSD_volume  XRPTUSD_pct_change  XRPTUSD_target  \\\n",
       "Time                                                                \n",
       "1581346800000        150520.2                 NaN               2   \n",
       "1581343200000         20433.0           -0.008154               2   \n",
       "1581339600000          9748.0           -0.007819               2   \n",
       "1581336000000         13476.4            0.001178               2   \n",
       "1581332400000          9632.8           -0.006657               2   \n",
       "\n",
       "               LTCTUSD_close  LTCTUSD_volume  LTCTUSD_pct_change  \\\n",
       "Time                                                               \n",
       "1581346800000          74.87      1236.85021                 NaN   \n",
       "1581343200000          74.44       300.63211           -0.005743   \n",
       "1581339600000          73.41       227.99520           -0.013837   \n",
       "1581336000000          73.49        91.53713            0.001090   \n",
       "1581332400000          73.05       267.58230           -0.005987   \n",
       "\n",
       "               LTCTUSD_target  EOSTUSD_close  EOSTUSD_volume  \\\n",
       "Time                                                           \n",
       "1581346800000               2         4.9057          138.60   \n",
       "1581343200000               2         4.9100           20.00   \n",
       "1581339600000               0         4.8321          760.33   \n",
       "1581336000000               2         4.8150          176.16   \n",
       "1581332400000               2         4.7682          523.45   \n",
       "\n",
       "               EOSTUSD_pct_change  EOSTUSD_target  \n",
       "Time                                               \n",
       "1581346800000                 NaN               2  \n",
       "1581343200000            0.000877               2  \n",
       "1581339600000           -0.015866               0  \n",
       "1581336000000           -0.003539               2  \n",
       "1581332400000           -0.009720               2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BTCTUSD_close', 'BTCTUSD_volume', 'BTCTUSD_target', 'ETHTUSD_close',\n",
       "       'ETHTUSD_volume', 'ETHTUSD_target', 'XRPTUSD_close', 'XRPTUSD_volume',\n",
       "       'XRPTUSD_target', 'LTCTUSD_close', 'LTCTUSD_volume', 'LTCTUSD_target',\n",
       "       'EOSTUSD_close', 'EOSTUSD_volume', 'EOSTUSD_target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = crp_df[crp_df.columns.drop(list(crp_df.filter(regex='pct')))]\n",
    "for col in df.columns:  # go through all of the columns\n",
    "    if not 'target' in col:  # normalize all ... except for the target itself!\n",
    "        df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "        df.fillna(method='ffill')  # remove the nas created by pct_change\n",
    "        df = df.replace([np.inf, -np.inf], 0)\n",
    "        df.fillna(0, inplace=True)\n",
    "        df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "    \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCTUSD_close</th>\n",
       "      <th>BTCTUSD_volume</th>\n",
       "      <th>BTCTUSD_target</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "      <th>ETHTUSD_volume</th>\n",
       "      <th>ETHTUSD_target</th>\n",
       "      <th>XRPTUSD_close</th>\n",
       "      <th>XRPTUSD_volume</th>\n",
       "      <th>XRPTUSD_target</th>\n",
       "      <th>LTCTUSD_close</th>\n",
       "      <th>LTCTUSD_volume</th>\n",
       "      <th>LTCTUSD_target</th>\n",
       "      <th>EOSTUSD_close</th>\n",
       "      <th>EOSTUSD_volume</th>\n",
       "      <th>EOSTUSD_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581346800000</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>-0.285455</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>-0.135991</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>-0.111854</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.118777</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>-0.094960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581343200000</th>\n",
       "      <td>-0.869334</td>\n",
       "      <td>-0.604839</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.817064</td>\n",
       "      <td>-0.082808</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.203838</td>\n",
       "      <td>-0.127130</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.666561</td>\n",
       "      <td>-0.134589</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103169</td>\n",
       "      <td>-0.109624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581339600000</th>\n",
       "      <td>-1.046867</td>\n",
       "      <td>-0.221000</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.553171</td>\n",
       "      <td>-0.148960</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.154752</td>\n",
       "      <td>-0.121097</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.614386</td>\n",
       "      <td>-0.123824</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.661187</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581336000000</th>\n",
       "      <td>0.512761</td>\n",
       "      <td>-0.348521</td>\n",
       "      <td>2</td>\n",
       "      <td>0.225019</td>\n",
       "      <td>-0.164074</td>\n",
       "      <td>2</td>\n",
       "      <td>0.164059</td>\n",
       "      <td>-0.105093</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133669</td>\n",
       "      <td>-0.131279</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.362141</td>\n",
       "      <td>-0.108127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581332400000</th>\n",
       "      <td>-0.575947</td>\n",
       "      <td>0.231466</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.228835</td>\n",
       "      <td>-0.148953</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.984509</td>\n",
       "      <td>-0.116895</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.695127</td>\n",
       "      <td>-0.078603</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.013500</td>\n",
       "      <td>-0.061175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BTCTUSD_close  BTCTUSD_volume  BTCTUSD_target  ETHTUSD_close  \\\n",
       "Time                                                                          \n",
       "1581346800000       0.000834       -0.285455               2       0.007351   \n",
       "1581343200000      -0.869334       -0.604839               2      -0.817064   \n",
       "1581339600000      -1.046867       -0.221000               2      -2.553171   \n",
       "1581336000000       0.512761       -0.348521               2       0.225019   \n",
       "1581332400000      -0.575947        0.231466               2      -1.228835   \n",
       "\n",
       "               ETHTUSD_volume  ETHTUSD_target  XRPTUSD_close  XRPTUSD_volume  \\\n",
       "Time                                                                           \n",
       "1581346800000       -0.135991               2      -0.008669       -0.111854   \n",
       "1581343200000       -0.082808               2      -1.203838       -0.127130   \n",
       "1581339600000       -0.148960               0      -1.154752       -0.121097   \n",
       "1581336000000       -0.164074               2       0.164059       -0.105093   \n",
       "1581332400000       -0.148953               2      -0.984509       -0.116895   \n",
       "\n",
       "               XRPTUSD_target  LTCTUSD_close  LTCTUSD_volume  LTCTUSD_target  \\\n",
       "Time                                                                           \n",
       "1581346800000               2       0.006044       -0.118777               2   \n",
       "1581343200000               2      -0.666561       -0.134589               2   \n",
       "1581339600000               2      -1.614386       -0.123824               0   \n",
       "1581336000000               2       0.133669       -0.131279               2   \n",
       "1581332400000               2      -0.695127       -0.078603               2   \n",
       "\n",
       "               EOSTUSD_close  EOSTUSD_volume  EOSTUSD_target  \n",
       "Time                                                          \n",
       "1581346800000       0.010796       -0.094960               2  \n",
       "1581343200000       0.103169       -0.109624               2  \n",
       "1581339600000      -1.661187        0.539394               0  \n",
       "1581336000000      -0.362141       -0.108127               2  \n",
       "1581332400000      -1.013500       -0.061175               2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "1581346800000    2\n",
       "1581343200000    2\n",
       "1581339600000    2\n",
       "1581336000000    2\n",
       "1581332400000    2\n",
       "1581328800000    2\n",
       "1581325200000    2\n",
       "1581321600000    2\n",
       "1581318000000    2\n",
       "1581314400000    2\n",
       "1581310800000    0\n",
       "1581307200000    1\n",
       "1581303600000    2\n",
       "1581300000000    2\n",
       "1581296400000    2\n",
       "Name: XRPTUSD_target, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['XRPTUSD_target'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "1581346800000    NaN\n",
       "1581343200000    NaN\n",
       "1581339600000    NaN\n",
       "1581336000000    NaN\n",
       "1581332400000    NaN\n",
       "1581328800000    NaN\n",
       "1581325200000    NaN\n",
       "1581321600000    NaN\n",
       "1581318000000    NaN\n",
       "1581314400000    NaN\n",
       "1581310800000    NaN\n",
       "1581307200000    NaN\n",
       "1581303600000    NaN\n",
       "1581300000000    NaN\n",
       "1581296400000    NaN\n",
       "1581292800000    NaN\n",
       "1581289200000    NaN\n",
       "1581285600000    NaN\n",
       "1581282000000    NaN\n",
       "1581278400000    NaN\n",
       "1581274800000    NaN\n",
       "1581271200000    NaN\n",
       "1581267600000    NaN\n",
       "1581264000000    NaN\n",
       "1581260400000    2.0\n",
       "Name: XRPTUSD_target, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['XRPTUSD_target'].shift(24).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_neur_ntw_target(symbol):\n",
    "    df_nn = df.copy()\n",
    "    symbol = symbol + '_target'\n",
    "    df_nn[symbol] = df_nn[symbol].shift(24)\n",
    "    df_nn.dropna(inplace=True)\n",
    "    \n",
    "    return df_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = neural_neur_ntw_target('XRPTUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTCTUSD_close</th>\n",
       "      <th>BTCTUSD_volume</th>\n",
       "      <th>BTCTUSD_target</th>\n",
       "      <th>ETHTUSD_close</th>\n",
       "      <th>ETHTUSD_volume</th>\n",
       "      <th>ETHTUSD_target</th>\n",
       "      <th>XRPTUSD_close</th>\n",
       "      <th>XRPTUSD_volume</th>\n",
       "      <th>XRPTUSD_target</th>\n",
       "      <th>LTCTUSD_close</th>\n",
       "      <th>LTCTUSD_volume</th>\n",
       "      <th>LTCTUSD_target</th>\n",
       "      <th>EOSTUSD_close</th>\n",
       "      <th>EOSTUSD_volume</th>\n",
       "      <th>EOSTUSD_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581260400000</th>\n",
       "      <td>-0.069258</td>\n",
       "      <td>-0.080171</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.575461</td>\n",
       "      <td>-0.121436</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.711333</td>\n",
       "      <td>-0.072111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.742516</td>\n",
       "      <td>-0.132462</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.521244</td>\n",
       "      <td>-0.044424</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581256800000</th>\n",
       "      <td>-0.413900</td>\n",
       "      <td>-0.555723</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.597468</td>\n",
       "      <td>-0.164268</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.447988</td>\n",
       "      <td>-0.112671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.147706</td>\n",
       "      <td>-0.096997</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.352827</td>\n",
       "      <td>-0.105049</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581253200000</th>\n",
       "      <td>0.295202</td>\n",
       "      <td>-0.468765</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>-0.130898</td>\n",
       "      <td>2</td>\n",
       "      <td>1.182107</td>\n",
       "      <td>-0.120454</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.775805</td>\n",
       "      <td>-0.135802</td>\n",
       "      <td>2</td>\n",
       "      <td>0.734121</td>\n",
       "      <td>-0.108657</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581249600000</th>\n",
       "      <td>0.319750</td>\n",
       "      <td>0.450077</td>\n",
       "      <td>2</td>\n",
       "      <td>0.768039</td>\n",
       "      <td>-0.139576</td>\n",
       "      <td>2</td>\n",
       "      <td>0.199469</td>\n",
       "      <td>-0.112095</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>-0.133405</td>\n",
       "      <td>2</td>\n",
       "      <td>0.149359</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581246000000</th>\n",
       "      <td>-0.313909</td>\n",
       "      <td>-0.310217</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.514601</td>\n",
       "      <td>-0.106181</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>-0.108727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.127608</td>\n",
       "      <td>-0.085940</td>\n",
       "      <td>2</td>\n",
       "      <td>0.347168</td>\n",
       "      <td>-0.105859</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BTCTUSD_close  BTCTUSD_volume  BTCTUSD_target  ETHTUSD_close  \\\n",
       "Time                                                                          \n",
       "1581260400000      -0.069258       -0.080171               2      -0.575461   \n",
       "1581256800000      -0.413900       -0.555723               2      -0.597468   \n",
       "1581253200000       0.295202       -0.468765               2       0.990881   \n",
       "1581249600000       0.319750        0.450077               2       0.768039   \n",
       "1581246000000      -0.313909       -0.310217               2      -0.514601   \n",
       "\n",
       "               ETHTUSD_volume  ETHTUSD_target  XRPTUSD_close  XRPTUSD_volume  \\\n",
       "Time                                                                           \n",
       "1581260400000       -0.121436               2      -0.711333       -0.072111   \n",
       "1581256800000       -0.164268               2      -0.447988       -0.112671   \n",
       "1581253200000       -0.130898               2       1.182107       -0.120454   \n",
       "1581249600000       -0.139576               2       0.199469       -0.112095   \n",
       "1581246000000       -0.106181               2       0.012115       -0.108727   \n",
       "\n",
       "               XRPTUSD_target  LTCTUSD_close  LTCTUSD_volume  LTCTUSD_target  \\\n",
       "Time                                                                           \n",
       "1581260400000             2.0      -0.742516       -0.132462               2   \n",
       "1581256800000             2.0      -0.147706       -0.096997               2   \n",
       "1581253200000             2.0       0.775805       -0.135802               2   \n",
       "1581249600000             2.0       0.770779       -0.133405               2   \n",
       "1581246000000             2.0       0.127608       -0.085940               2   \n",
       "\n",
       "               EOSTUSD_close  EOSTUSD_volume  EOSTUSD_target  \n",
       "Time                                                          \n",
       "1581260400000      -0.521244       -0.044424               2  \n",
       "1581256800000      -0.352827       -0.105049               2  \n",
       "1581253200000       0.734121       -0.108657               2  \n",
       "1581249600000       0.149359        0.002295               2  \n",
       "1581246000000       0.347168       -0.105859               2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['BTCTUSD_target' 'ETHTUSD_target' 'LTCTUSD_target' 'EOSTUSD_target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-aad4d57f2805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BTCTUSD_target'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ETHTUSD_target'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LTCTUSD_target'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EOSTUSD_target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3111\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4404\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['BTCTUSD_target' 'ETHTUSD_target' 'LTCTUSD_target' 'EOSTUSD_target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. \n",
    "df_target = df_target[[c for c in df_target if c not in ['XRPTUSD_target']] + ['XRPTUSD_target']]\n",
    "df_target\n",
    "\n",
    "df_target = df_target.drop(['BTCTUSD_target','ETHTUSD_target','LTCTUSD_target', 'EOSTUSD_target'], axis=1)\n",
    "df_target.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_target.values:  # iterate over the values\n",
    "    prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "    if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "        sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "buys = []  # list that will store our buy sequences and targets\n",
    "sells = []  # list that will store our sell sequences and targets\n",
    "holds = []  # list that will store our sell sequences and targets\n",
    "\n",
    "for seq, target in sequential_data:  # iterate over the sequential data\n",
    "    if target == 0:  # if it's a \"not buy\"\n",
    "        sells.append([seq, target])  # append to sells list\n",
    "    elif target == 1:  # otherwise if the target is a 1...\n",
    "        buys.append([seq, target])  # it's a buy!\n",
    "    else:\n",
    "        holds.append([seq, target])\n",
    "\n",
    "random.shuffle(buys)  # shuffle the buys\n",
    "random.shuffle(sells)  # shuffle the sells!\n",
    "random.shuffle(holds)  # shuffle the holds!\n",
    "\n",
    "lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "\n",
    "buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "sequential_data = buys+sells+holds  # add them together\n",
    "random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq, target in sequential_data:  # going over our new sequential data\n",
    "    X.append(seq)  # X is the sequences\n",
    "    y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "#return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_neur_net_df(df):\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. \n",
    "    df = df[[c for c in df if c not in ['XRPTUSD_target']] + ['XRPTUSD_target']]\n",
    "    for i in df.drop(['BTCTUSD_target','ETHTUSD_target','LTCTUSD_target', 'EOSTUSD_target'], axis=1).values:\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "    \n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "    holds = []  # list that will store our sell sequences and targets\n",
    "    \n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "        else:\n",
    "            holds.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "    random.shuffle(holds)  # shuffle the holds!\n",
    "    \n",
    "    lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "    \n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    \n",
    "    sequential_data = buys+sells+holds  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_neur_net_df(df):\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. \n",
    "\n",
    "    df = df[[c for c in df if c not in ['XRPTUSD_target']] + ['XRPTUSD_target']]\n",
    "    for i in df.drop(['BTCTUSD_target','ETHTUSD_target','LTCTUSD_target', 'EOSTUSD_target'], axis=1).values:\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[:-1]])  # append those bad boys!\n",
    "    \n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "    holds = []  # list that will store our sell sequences and targets\n",
    "    \n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "        else:\n",
    "            holds.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "    random.shuffle(holds)  # shuffle the holds!\n",
    "    \n",
    "    lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "    \n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    \n",
    "    sequential_data = buys+sells+holds  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. \n",
    "buys = []  # list that will store our buy sequences and targets\n",
    "sells = []  # list that will store our sell sequences and targets\n",
    "holds = []  # list that will store our sell sequences and targets\n",
    "\n",
    "for seq, target in sequential_data:  # iterate over the sequential data\n",
    "    if target == 0:  # if it's a \"not buy\"\n",
    "        sells.append([seq, target])  # append to sells list\n",
    "    elif target == 1:  # otherwise if the target is a 1...\n",
    "        buys.append([seq, target])  # it's a buy!\n",
    "    else:\n",
    "        holds.append([seq, target])\n",
    "\n",
    "random.shuffle(buys)  # shuffle the buys\n",
    "random.shuffle(sells)  # shuffle the sells!\n",
    "random.shuffle(holds)  # shuffle the holds!\n",
    "\n",
    "lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "\n",
    "buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "sequential_data = buys+sells+holds  # add them together\n",
    "random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq, target in sequential_data:  # going over our new sequential data\n",
    "    X.append(seq)  # X is the sequences\n",
    "    y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buys = []  # list that will store our buy sequences and targets\n",
    "sells = []  # list that will store our sell sequences and targets\n",
    "holds = []  # list that will store our sell sequences and targets\n",
    "\n",
    "for seq, target in sequential_data:  # iterate over the sequential data\n",
    "    if target == 0:  # if it's a \"not buy\"\n",
    "        sells.append([seq, target])  # append to sells list\n",
    "    elif target == 1:  # otherwise if the target is a 1...\n",
    "        buys.append([seq, target])  # it's a buy!\n",
    "    else:\n",
    "        holds.append([seq, target])\n",
    "\n",
    "random.shuffle(buys)  # shuffle the buys\n",
    "random.shuffle(sells)  # shuffle the sells!\n",
    "random.shuffle(holds)  # shuffle the holds!\n",
    "\n",
    "lower = min(len(buys), len(sells), len(holds))  # what's the shorter length?\n",
    "\n",
    "buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "holds = holds[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "sequential_data = buys+sells+holds  # add them together\n",
    "random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq, target in sequential_data:  # going over our new sequential data\n",
    "    X.append(seq)  # X is the sequences\n",
    "    y.append(target)  # y is the targets/labels (buys vs sell/notbuy vs holds)\n",
    "\n",
    "return np.array(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(df_target.index.values)  # get the times\n",
    "last_20pct = sorted(df_target.index.values)[-int(0.2*len(times))]  # get the last 20% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_main_df = df_target[(df_target.index >= last_20pct)]  # make the validation data where the index is in the last 5%\n",
    "main_df = df_target[(df_target.index < last_20pct)]  # now the main_df is all the data up to the last 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = preprocess_neur_net_df(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x, train_y = preprocess_neur_net_df(main_df)\n",
    "validation_x, validation_y = preprocess_neur_net_df(validation_main_df)\n",
    "\n",
    "print(f\"Train data: {len(train_x)} Validation: {len(validation_x)}\")\n",
    "print(f\"Sells: {train_y.count(0)}, Holds: {train_y.count(2)}, Buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Sells: {validation_y.count(0)}, Holds: {validation_y.count(2)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20  # how many passes through our data\n",
    "BATCH_SIZE = 64  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've normalized and scaled the data! Next up, we need to create our actual sequences. To do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "\n",
    "filepath = \"LSTM_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "# unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) \n",
    "# saves only the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
