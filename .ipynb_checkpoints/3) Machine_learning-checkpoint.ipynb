{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our heatmap we saw that there is correlation in terms of closing price between different cryptocurrencies.\n",
    "\n",
    "The question now is, can we get a machine learning in order to recognize those relationship?\n",
    "\n",
    "As we saw group of companies are likely to move together either up or down but not necesserily at the same time.\n",
    "Most of the times people try to get a price prediction based on the history of that only cryptocurrency.\n",
    "In our case being this previous approach almost always useless we will try to get a prediction using numerous cryptocurrencies to see if we can get a real edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import itertools\n",
    "import operator\n",
    "from matplotlib import style\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we create a function that's gonna define the number of hours we want in the future in order to get a hold, buy or sell label.\n",
    "\n",
    "Doing so we are creating in our case 3 extra columns that are gonna be our lagged prices in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_labels(symbol):\n",
    "    '''Create n columns containing the values of the price difference normalized\n",
    "       based on the hours we want to predict in future\n",
    "    \n",
    "       Args:\n",
    "           symbol: cryptocurrency timeseries we want to predict\n",
    "           \n",
    "       Returns:\n",
    "           hours: hours in the future we want to predict\n",
    "           symbols: cryptocurrency timeseries we want to predict\n",
    "           df: df containing 500 cryptocurrencies with new columns\n",
    "    '''\n",
    "    hours = 3\n",
    "    df = pd.read_csv('500crypto_joined_close.csv', index_col=0)\n",
    "    symbols = df.columns.values.tolist()\n",
    "    \n",
    "    for i in range(1, hours+1):\n",
    "        df[f'{symbol}_{i}h'] = (df[symbol].shift(-i) - df[symbol]) / df[symbol]\n",
    "        \n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return hours, symbols, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours, symbols, df = process_data_for_labels('ETHBTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labels buy, hold, sell for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create buy, hold, sell labels based on a % change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    '''Return 1, 0, -1 based on % change\n",
    "    \n",
    "       Args:\n",
    "           *args: pass any number of parameters\n",
    "    '''\n",
    "    cols = [c for c in args]\n",
    "    change_perc = 0.03\n",
    "    for col in cols:\n",
    "        if col > change_perc:\n",
    "            return 1\n",
    "        if col < -change_perc:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_sets(symbol):\n",
    "    '''Create feature sets y and X\n",
    "    \n",
    "       Args:\n",
    "           symbol: cryptocurrency timeseries we want to predict\n",
    "           \n",
    "       Returns:\n",
    "           X: Percentage change in data fo all of the cryptocurrencies including company in question\n",
    "           y: labels 1, 0, -1\n",
    "           df: df containing 500 cryptocurrencies with new columns\n",
    "    '''\n",
    "    \n",
    "    hours, symbols, df = process_data_for_labels(symbol)\n",
    "    \n",
    "    df[f'{symbol}_target'] = list(map(buy_sell_hold, *[df[f'{symbol}_{i}h'] for i in range(1, hours+1)]))\n",
    "    \n",
    "    labels = df[f'{symbol}_target'].values.tolist()\n",
    "    str_labels = [str(i) for i in labels]\n",
    "    print('Data Spread: ', Counter(str_labels))\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Create Feature Sets\n",
    "    # Percentage change in data for all of the cryptocurrencies including company in question\n",
    "    df_vals = df[[symbol for symbol in symbols]].pct_change()\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "    #df_vals.drop(df_vals.columns[[-2, -3, -4]], axis = 1, inplace = True) \n",
    "    \n",
    "    X = df_vals.values\n",
    "    y = labels\n",
    "    \n",
    "    return X, y, df_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Spread:  Counter({'0': 2448, '-1': 28, '1': 20})\n"
     ]
    }
   ],
   "source": [
    "X, y, df_vals = extract_feature_sets('BTCUSDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_test, y_pred):\n",
    "    ''' Plot confusion matrix\n",
    "    \n",
    "        Args: \n",
    "            X: model features (df)\n",
    "            y: model target feature (df)\n",
    "            cw: weight class parameter classifier = balanced\n",
    "            avg: f1 metric\n",
    "            \n",
    "        Returns: \n",
    "            clf: fitted instance of LogReg classifier\n",
    "            y_pred: prediction made on X_test data (np array)\n",
    "            train_score_logreg: score for Train data (float)\n",
    "            test_score_logreg: score for Test data (float)\n",
    "    '''\n",
    "    \n",
    "    labels = [-1, 0, 1]\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred, labels)\n",
    "    \n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.imshow(cnf_matrix,  cmap=plt.cm.Blues, aspect='auto') #Create the basic matrix.\n",
    "    \n",
    "    #Add title and Axis Labels\n",
    "    plt.title('Confusion Matrix', fontsize=20)\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    \n",
    "    #Add appropriate Axis Scales\n",
    "    class_names = set(y) #Get class labels to add to matrix\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, fontsize=20)\n",
    "    plt.yticks(tick_marks, class_names, fontsize=20)\n",
    "    \n",
    "    #Add Labels to Each Cell\n",
    "    thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "    #Here we iterate through the confusion matrix and append labels to our visualization.\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            plt.text(j, i, cnf_matrix[i, j],\n",
    "                     horizontalalignment=\"center\",\n",
    "                     fontsize =18,\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "    \n",
    "    #Add a Side Bar Legend Showing Colors\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def log_regr(X, y ,cw='balanced', avg='macro'):\n",
    "    ''' train LogRegr Classifier and calculate score on Train and Test data\n",
    "    \n",
    "        Args: \n",
    "            X: model features (df)\n",
    "            y: model target feature (df)\n",
    "            cw: weight class parameter classifier = balanced\n",
    "            avg: f1 metric\n",
    "            \n",
    "        Returns: \n",
    "            clf: fitted instance of LogReg classifier\n",
    "            y_pred: prediction made on X_test data (np array)\n",
    "            train_score_logreg: score for Train data (float)\n",
    "            test_score_logreg: score for Test data (float)\n",
    "    '''\n",
    "    # Train a LogRegr classifier\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "    clf = LogisticRegression(random_state=10, class_weight=cw)\n",
    "                             \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate f1 score\n",
    "    \n",
    "    log_regr_f1_score = f1_score(y_test, y_pred, average=avg)\n",
    "    \n",
    "    # Calculate Score\n",
    "    train_score_logreg = clf.score(X_train, y_train)\n",
    "    test_score_logreg = clf.score(X_test, y_test)\n",
    "    print(\"LogReg Train score: \", train_score_logreg)\n",
    "    print(\"LogReg Test score: \", test_score_logreg)\n",
    "    print(f\"LogReg f1 Score: {log_regr_f1_score}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return clf, train_score_logreg, test_score_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def dec_tree(X, y, cw='balanced', avg='macro'):\n",
    "    ''' train DecTree Classifier using GridSearch and calculate score on Train and Test data\n",
    "    \n",
    "        Args: \n",
    "            X: model features (df)\n",
    "            y: model target feature (df)\n",
    "            cw: weight class parameter classifier = balance\n",
    "            avg: f1 metric\n",
    "            \n",
    "        Returns: \n",
    "            clf_dec_tree: fitted instance of DecisionTree classifier\n",
    "            dt_grid_search: fitted instance of GridSearch classifier\n",
    "            dt_gs_train_score: score for Train data (float)\n",
    "            dt_gs_testing_score: score for Test data (float)\n",
    "    '''\n",
    "    # Train a DT classifier\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    clf_dec_tree = DecisionTreeClassifier(random_state=10, class_weight=cw)  \n",
    "    clf_dec_tree.fit(X_train, y_train)  \n",
    "    \n",
    "    # GridSearch\n",
    "    dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "    }\n",
    "    \n",
    "    # Instantiate GridSearchCV\n",
    "    dt_grid_search = GridSearchCV(clf_dec_tree, dt_param_grid, cv=3, return_train_score=True)\n",
    "    dt_grid_search.fit(X_train, y_train)\n",
    "    y_pred = dt_grid_search.predict(X_test)\n",
    "    \n",
    "    # Calculate f1 score\n",
    "    \n",
    "    dt_gs_f1_score = f1_score(y_test, y_pred, average=avg)\n",
    "    \n",
    "    # Calculate Score\n",
    "    dt_gs_train_score = dt_grid_search.score(X_train, y_train)\n",
    "    dt_gs_testing_score = dt_grid_search.score(X_test, y_test)\n",
    "    print(\"DecTree GridSearch Train score: \", dt_gs_train_score)\n",
    "    print(\"DecTree GridSearch Test score: \", dt_gs_testing_score)\n",
    "    print(f\"Optimal Parameters: {dt_grid_search.best_params_}\")\n",
    "    print(f\"DecTree f1 Score: {dt_gs_f1_score}\" )\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    return clf_dec_tree, dt_grid_search, dt_gs_train_score, dt_gs_testing_score, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def rand_for(X, y, cw='balanced', avg='macro'):\n",
    "    ''' train RandFor Classifier using GridSearch, calculate score on Train and Test data and \n",
    "        Visualize feature importance\n",
    "    \n",
    "        Args: \n",
    "            X: model features (df)\n",
    "            y: model target feature (df)\n",
    "            cw: weight class parameter classifier = balanced\n",
    "            avg: f1 metric\n",
    "            \n",
    "        Returns: \n",
    "            rf_grid_search: fitted instance of GridSearch classifier\n",
    "            rf_gs_train_score: score for Train data (float)\n",
    "            rf_gs_testing_score: score for Test data (float)\n",
    "            rf_gs_f1_score: f1 score\n",
    "    '''\n",
    "    # Train a RF classifier\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    clf_rand_for = RandomForestClassifier(random_state=10, class_weight=cw)  \n",
    "    clf_rand_for.fit(X_train, y_train)  \n",
    "    \n",
    "    # GridSearch\n",
    "    rf_param_grid = {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [1, 3, 6]\n",
    "    }\n",
    "    \n",
    "    # Instantiate GridSearchCV\n",
    "    rf_grid_search = GridSearchCV(clf_rand_for, rf_param_grid, cv=3, scoring='f1_macro')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate Score\n",
    "    rf_gs_train_score = rf_grid_search.score(X_train, y_train)\n",
    "    rf_gs_testing_score = rf_grid_search.score(X_test, y_test)\n",
    "    y_pred_gs = rf_grid_search.predict(X_test)\n",
    "    \n",
    "    # Calculate f1 score\n",
    "    \n",
    "    rf_gs_f1_score = f1_score(y_test, y_pred_gs, average=avg)\n",
    "    \n",
    "    # Sort feature_importances in a graph\n",
    "    emp_dict = {}\n",
    "    for f, i in zip(df.columns, clf_rand_for[0].feature_importances_):\n",
    "        emp_dict[f] = i\n",
    "    sorted_feat_import = list( sorted(emp_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    \n",
    "    # Visualize feature_importances in a graph\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.barh([x[0] for x in sorted_feat_import[:30]], [x[1] for x in sorted_feat_import[:30]])\n",
    "    plt.title('Top 30 Feature Importances', fontsize=22)\n",
    "    plt.xlabel('Feature Weight', fontsize=20)\n",
    "    plt.ylabel('Feature', fontsize=20)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show();\n",
    "    \n",
    "    print(\"RandFor GridSearch Train score: \", rf_gs_train_score)\n",
    "    print(\"RandFor GridSearch Test score: \", rf_gs_testing_score)\n",
    "    print(f\"RandFore GridSearch f1 Score: {rf_gs_f1_score}\")\n",
    "    print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return  clf_rand_for, rf_grid_search, rf_gs_train_score, rf_gs_testing_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_for(X, y, cw='balanced', avg='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do machine learning tweaking several parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML class_weight = 'balanced' & f1 metric = 'macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning(X, y, cw='balanced', avg='macro'):\n",
    "    ''' runs log_regr, dec_tree and rand_for functions\n",
    "    \n",
    "        print Confusion Matrices for Logistic Regression and Random Forest\n",
    "    \n",
    "        Args: \n",
    "            X: model features (df)\n",
    "            y: model target feature (df)\n",
    "        \n",
    "    '''    \n",
    "    clf, train_score_logreg, test_score_logreg = log_regr(X, y, cw='balanced', avg='micro')\n",
    "    clf_dec_tree, dt_grid_search, dt_gs_train_score, dt_gs_testing_score, y_test, y_pred = dec_tree(X, y, cw='balanced', avg='micro')\n",
    "    clf_rand_for, rf_grid_search, rf_gs_train_score, rf_gs_testing_score= rand_for(X, y, cw='balanced', avg='micro')\n",
    "    \n",
    "    #Create and print a confusion matrix \n",
    "    conf_matrix(y_test, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "machine_learning(X, y, cw=None, avg=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML class_weight = 'balanced' & f1 metric = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning(X, y, cw='balanced', avg=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML class_weight = 'balanced' & f1 metric = 'micro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning(X, y, cw='balanced', avg='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw from our machine learning models also if we tweak our parameter we always obtain a really high accuracy and f1 score.\n",
    "\n",
    "Also if this might seem a pretty good result we need to consider that all the models are clearly overfitting due to the imbalanced classes.\n",
    "\n",
    "In the next step I am going to balance our classes manually tweaking the % change in prices and see if we can obtain a more realistic result.\n",
    "\n",
    "It is worthed to mention that in order to balance our classes in this way we need to lower the % change in price.\n",
    "In this case only a trading bot will be able to apply this strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    '''Return 1, 0, -1 based on % change\n",
    "    \n",
    "       Args:\n",
    "           *args: pass any number of parameters\n",
    "    '''\n",
    "    cols = [c for c in args]\n",
    "    change_perc = 0.005\n",
    "    for col in cols:\n",
    "        if col > change_perc:\n",
    "            return 1\n",
    "        if col < -change_perc:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, df = extract_feature_sets('ETHUSDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning(X, y, cw=None, avg='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see logistic regression is able to have a little edge over the 33% that we would expect from random guessing but just of 2%.\n",
    "\n",
    "Tweaking a bit the model makes us doing slighly better.\n",
    "\n",
    "We do need moreover to take in consideration that if our model is also capable of doing 7/8% better the risk of losing everything when the model is not performing well is really high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison table between algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Algorithm            | Accuracy |  \n",
    "|:-------------:       |------:        |        \n",
    "|  Logistic regression | 0.34        |\n",
    "|    Decision tree     |   0.38        | \n",
    "| Random forest        |    0.48        |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next notebook I will try using Neural Network trying to improve the score obtained through machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
