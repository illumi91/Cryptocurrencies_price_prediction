{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LF-invest is a financial company mainly specialised in real estate and stocks market.\n",
    "\n",
    "Considering the new opportunities deriving from the cryptocurrencies market and the potential future enlargement of it we have been asked to develop a trading model applicable in a real world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "import requests \n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import decimal\n",
    "import hmac\n",
    "import time\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "%matplotlib inline\n",
    "import mplfinance as mpf\n",
    "import mpl_finance\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is D816-28B0\n",
      "\n",
      " Directory of C:\\Users\\luigi\\FlatironSchool\\Module06\\Project\\dsc-capstone-project-v2-online-ds-pt-051319\n",
      "\n",
      "19/03/2020  12:24    <DIR>          .\n",
      "19/03/2020  12:24    <DIR>          ..\n",
      "19/03/2020  12:24    <DIR>          .ipynb_checkpoints\n",
      "18/03/2020  16:37        14,214,202 1) EDA & visualizations.ipynb\n",
      "18/03/2020  12:56           207,243 2) Time_series_prediction.ipynb\n",
      "18/03/2020  11:46           326,662 3) Machine_learning.ipynb\n",
      "19/03/2020  12:23            20,814 4) Neural_network_prediction.ipynb\n",
      "18/03/2020  16:36        13,148,480 500crypto_joined_close.csv\n",
      "21/02/2020  12:53    <DIR>          crypto_dfs\n",
      "18/03/2020  16:21    <DIR>          crypto_project_images\n",
      "18/03/2020  16:36             7,538 crypto_tickers.pickle\n",
      "18/03/2020  16:01         1,675,381 Cryptocurrencies_pred_presentation.pdf\n",
      "19/03/2020  12:23    <DIR>          data_BTCUSD\n",
      "19/03/2020  12:22    <DIR>          logs\n",
      "19/03/2020  12:24    <DIR>          models\n",
      "18/03/2020  16:56             5,328 README.md\n",
      "               8 File(s)     29,605,648 bytes\n",
      "               8 Dir(s)  16,718,995,456 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trading data for BTCUSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request from Binance API symbol's with hourly interval and create a df.\n",
    "Increasing the range gives us further data in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_arima/btcusd.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-396bf408b2a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mdf_btcusd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_btcusd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ms'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mdf_btcusd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data_arima/btcusd.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_arima/btcusd.csv'"
     ]
    }
   ],
   "source": [
    "df_btcusd = pd.DataFrame()\n",
    "\n",
    "for x in range(5):\n",
    "    \n",
    "    if x == 0: \n",
    "    \n",
    "        response = requests.get('https://api.binance.com/api/v1/klines?symbol=BTCUSDT&interval=1h')\n",
    "        data_symbol = json.loads(response.text)\n",
    "\n",
    "        # put in dataframe and drop columns we don't neeed\n",
    "        df = pd.DataFrame.from_dict(data_symbol)\n",
    "        df = df.drop(range(6, 12), axis=1)\n",
    "\n",
    "        # rename columns\n",
    "        col_names = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        df.columns = col_names\n",
    "\n",
    "        # transform values from strings to floats\n",
    "        for col in col_names[1:6]:\n",
    "            df[col] = df[col].astype(float)\n",
    "            \n",
    "        df = df.sort_values(by='Time', ascending=False, kind='quicksort')\n",
    "            \n",
    "        df_btcusd = df_btcusd.append(df)\n",
    "        \n",
    "        timestamp = int(df.loc[0, 'Time'])\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        response = requests.get(f'https://api.binance.com/api/v1/klines?symbol=BTCUSDT&interval=1h&endTime={timestamp}')\n",
    "        data_symbol = json.loads(response.text)\n",
    "        \n",
    "        # put in dataframe and drop columns we don't neeed\n",
    "        df1 = pd.DataFrame.from_dict(data_symbol)\n",
    "        df1 = df1.drop(range(6, 12), axis=1)\n",
    "        \n",
    "        # rename columns\n",
    "        col_names = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        df1.columns = col_names\n",
    "        \n",
    "        # transform values from strings to floats\n",
    "        for col in col_names[1:6]:\n",
    "            df1[col] = df1[col].astype(float)\n",
    "            \n",
    "        df1.drop(499, inplace=True)\n",
    "        \n",
    "        df1 = df1.sort_values(by='Time', ascending=False, kind='quicksort')\n",
    "        \n",
    "        df_btcusd = df_btcusd.append(df1)\n",
    "        \n",
    "        df_btcusd.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        timestamp = int(df1.loc[0, 'Time'])\n",
    "        \n",
    "df_btcusd['Date'] = pd.to_datetime(df_btcusd['Time'], unit='ms')\n",
    "\n",
    "df_btcusd.to_csv('./data_arima/btcusd.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot candlestick using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle = go.Candlestick(\n",
    "            x = df_btcusd['Date'],\n",
    "            open = df_btcusd['Open'],\n",
    "            close = df_btcusd['Close'],\n",
    "            high = df_btcusd['High'],\n",
    "            low = df_btcusd['Low'],\n",
    "            name = \"Candlesticks\")\n",
    "\n",
    "fig = go.Figure(data=[candle])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd.drop(columns='Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd = df_btcusd.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd = df_btcusd.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw the 2020-03-12 at 09:00:00 the prices due to the corona virus are suffering a fall.\n",
    "\n",
    "I am for this reason removing the data after that point going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd = df_btcusd[df_btcusd.index < '2020-03-12 09:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot BTCUSD using interactive Plotly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btcusd['Close'].iplot(mode='lines+text',\n",
    "                        xTitle='Time',\n",
    "                        yTitle='Price', \n",
    "                        title='Hourly BTCUSD Close',\n",
    "                        opacity=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot BTCUSD & moving avg using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# Moving Average 100\n",
    "df_btcusd['100MA'] = df_btcusd['Close'].rolling(window=100, min_periods=0).mean()\n",
    "\n",
    "ax1 = plt.subplot2grid((6, 1), (0, 0), rowspan=5, colspan=1)\n",
    "ax2 = plt.subplot2grid((6, 1), (5, 0), rowspan=1, colspan=1, sharex=ax1)\n",
    "\n",
    "ax1.plot(df_btcusd.index, df_btcusd['Close'], df_btcusd['100MA'])\n",
    "ax2.bar(df_btcusd.index, df_btcusd['Volume'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample close and volume colums by 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc = df_btcusd['Close'].resample('1d').ohlc()\n",
    "df_volume = df_btcusd['Volume'].resample('1d').sum()\n",
    "df_ohlc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change date to matplotlib timestamp to plot ohlc candlestick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc.index = df_ohlc.index.map(mdates.date2num)\n",
    "df_ohlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc.reset_index(inplace=True)\n",
    "df_ohlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc.columns = [['Date', 'Open', 'High', 'Low', 'Close']]\n",
    "df_ohlc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot candlestick using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax1 = plt.subplot2grid((6, 1), (0, 0), rowspan=5, colspan=1)\n",
    "ax2 = plt.subplot2grid((6, 1), (5, 0), rowspan=1, colspan=1, sharex=ax1)\n",
    "\n",
    "\n",
    "\n",
    "candlestick_ohlc(ax1, df_ohlc.values, width=2, colorup='g', colordown='r')\n",
    "ax1.grid(True)\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.set_title('BTC Share Price', color='white', fontsize=27)\n",
    "ax1.set_facecolor('black')\n",
    "ax1.figure.set_facecolor('#121212')\n",
    "ax1.tick_params(axis='x', colors='white')\n",
    "ax1.tick_params(axis='y', colors='white')\n",
    "ax1.axes.get_xaxis().set_visible(False)\n",
    "ax1.set_ylabel('Price', fontsize = 20) \n",
    "\n",
    "ax1.plot(df_btcusd['Close'].rolling(window=100).mean(), color='b',  label='100MA')\n",
    "ax1.legend(loc=\"upper right\", fontsize=15)\n",
    "\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "ax1.xaxis_date()\n",
    "\n",
    "\n",
    "ax2.fill_between(df_volume.index.map(mdates.date2num), df_volume.values, 0, color = 'magenta',  label='Volume')\n",
    "ax2.set_ylabel('Volume', fontsize = 20) \n",
    "ax2.tick_params(axis='x', colors='white')\n",
    "ax2.tick_params(axis='y', colors='white')\n",
    "ax2.grid(True)\n",
    "ax2.set_facecolor('black')\n",
    "ax2.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All Trading (currently) Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trading_symbols():\n",
    "    '''\n",
    "     Get trading symbols from Binance API\n",
    "\n",
    "     Returns: \n",
    "         symbols: symbols actively traded in Binance\n",
    "    '''\n",
    "    \n",
    "    response = requests.get('https://api.binance.com' + '/api/v1/exchangeInfo')\n",
    "    data_symbols = json.loads(response.text)\n",
    "    \n",
    "    symbols = []\n",
    "\n",
    "    for x in data_symbols['symbols']:\n",
    "        if x['status'] == 'TRADING':\n",
    "            symbols.append(x['symbol'])\n",
    "            \n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = get_trading_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data for all the Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 500 symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = symbols[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pickle object so that later we can reference it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crypto_tickers.pickle', 'wb') as f:\n",
    "    pickle.dump(symbols, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_binance(reload_symbols=False):\n",
    "    '''\n",
    "     Get data for each cryptocurrency, increasing range gives us further data in the past\n",
    "     \n",
    "     Args: \n",
    "         reload_symbols: check if path with symbols already exists, if not it calls function to get symbols\n",
    "    '''\n",
    "    \n",
    "    if reload_symbols:\n",
    "        symbols = get_trading_symbols()\n",
    "    else:\n",
    "        with open('crypto_tickers.pickle', 'rb') as f:\n",
    "            symbols = pickle.load(f)\n",
    "            \n",
    "    if not os.path.exists('crypto_dfs'):\n",
    "        os.makedirs('crypto_dfs')\n",
    "        \n",
    "    for symbol in symbols:\n",
    "        \n",
    "        print(symbol)\n",
    "        \n",
    "        if not os.path.exists('crypto_dfs/{}.csv'.format(symbol)):\n",
    "            \n",
    "            \n",
    "            df_crypto = pd.DataFrame()\n",
    "\n",
    "            for x in range(5):\n",
    "\n",
    "                if x == 0: \n",
    "\n",
    "                    response = requests.get(f'https://api.binance.com/api/v1/klines?symbol={symbol}&interval=1h')\n",
    "                    data_symbol = json.loads(response.text)\n",
    "\n",
    "                    # put in dataframe and drop columns we don't neeed\n",
    "                    df = pd.DataFrame.from_dict(data_symbol)\n",
    "                    df = df.drop(range(6, 12), axis=1)\n",
    "\n",
    "                    # rename columns\n",
    "                    col_names = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "                    df.columns = col_names\n",
    "\n",
    "                    # transform values from strings to floats\n",
    "                    for col in col_names[1:6]:\n",
    "                        df[col] = df[col].astype(float)\n",
    "\n",
    "                    df = df.sort_values(by='Time', ascending=False, kind='quicksort')\n",
    "\n",
    "                    df_crypto = df_crypto.append(df)\n",
    "\n",
    "                    timestamp = int(df.loc[0, 'Time'])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    response = requests.get(f'https://api.binance.com/api/v1/klines?symbol={symbol}&interval=1h&endTime={timestamp}')\n",
    "                    data_symbol = json.loads(response.text)\n",
    "\n",
    "                    # put in dataframe and drop columns we don't neeed\n",
    "                    df1 = pd.DataFrame.from_dict(data_symbol)\n",
    "                    df1 = df1.drop(range(6, 12), axis=1)\n",
    "\n",
    "                            # rename columns\n",
    "                    col_names = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "                    df1.columns = col_names\n",
    "\n",
    "                    # transform values from strings to floats\n",
    "                    for col in col_names[1:6]:\n",
    "                        df1[col] = df1[col].astype(float)\n",
    "\n",
    "                    df1.drop(df.tail(1).index,inplace=True)\n",
    "\n",
    "                    df1 = df1.sort_values(by='Time', ascending=False, kind='quicksort')\n",
    "\n",
    "                    df_crypto = df_crypto.append(df1)\n",
    "\n",
    "                    df_crypto.reset_index(drop = True, inplace = True)\n",
    "\n",
    "                    timestamp = int(df1.loc[0, 'Time'])\n",
    "                    \n",
    "\n",
    "            df_crypto['Date'] = pd.to_datetime(df_crypto['Time'], unit='ms')\n",
    "            \n",
    "            df_crypto.to_csv('crypto_dfs/{}.csv'.format(symbol))\n",
    "            \n",
    "        else:\n",
    "            print('Already have {}'.format(symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_from_binance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data():\n",
    "    '''\n",
    "     Create main_df containing close column for each symbol \n",
    "\n",
    "     Returns: \n",
    "         main_df: main_df contaning close column for each cryptocurrency\n",
    "    '''\n",
    "    with open('crypto_tickers.pickle', 'rb') as f:\n",
    "        symbols = pickle.load(f)\n",
    "    \n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for count, symbol in enumerate(symbols):\n",
    "        df =pd.read_csv(f'crypto_dfs/{symbol}.csv',  index_col=0)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        \n",
    "        df.rename(columns={'Close' : symbol}, inplace=True)\n",
    "        df.drop(['Time','Open','High','Low','Volume'], 1, inplace=True)\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "            \n",
    "        else:\n",
    "            main_df = main_df.join(df)\n",
    "            \n",
    "    print(main_df.head())    \n",
    "        \n",
    "    main_df.to_csv('500crypto_joined_close.csv')\n",
    "    \n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Relationship with different Cryptocurrencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correlation between all cryptocurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('500crypto_joined_close.csv')\n",
    "corrs = df.corr()\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    ''' Visualize correlation heatmap \n",
    "    '''\n",
    "    df = pd.read_csv('500crypto_joined_close.csv')\n",
    "    corrs = df.corr()\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                    z=corrs.values,\n",
    "                    x=list(corrs.columns),\n",
    "                    y=list(corrs.index),\n",
    "                    showscale=True,\n",
    "                    colorscale='Inferno',\n",
    "                    hoverongaps = False))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize interactive correlation heatmap using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will be going to do a prediction using time series modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
